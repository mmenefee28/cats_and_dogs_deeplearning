#!/usr/bin/env python
# coding: utf-8


# Import libraries

import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras import backend, models, layers, optimizers, regularizers
from tensorflow.keras.utils import to_categorical
import numpy as np
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from IPython.display import display  # Library to help view images
from PIL import Image
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Library for data augmentation
import os, shutil  # Library for navigating files

np.random.seed(42)

# Specify the base directory where images are located.  You need to save your data here.
base_dir = 'C:/Users/Thorus/gridworld2/MSDS686/dogs vs cats_small'

# Specify the traning, validation, and test dirrectories.
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')
test_dir = os.path.join(base_dir, 'test')

# Specify the the classess in the training, validataion, and test dirrectories
train_cats_dir = os.path.join(train_dir, 'cats')
train_dogs_dir = os.path.join(train_dir, 'dogs')

validation_cats_dir = os.path.join(validation_dir, 'cats')
validation_dogs_dir = os.path.join(validation_dir, 'dogs')

test_cats_dir = os.path.join(test_dir, 'cats')
test_dogs_dir = os.path.join(test_dir, 'dogs')

# We need to normalize the pixels in the images.  The data will 'flow' through this generator.
train_datagen = ImageDataGenerator(rescale=1. / 255)
test_datagen = ImageDataGenerator(rescale=1. / 255)

# set Epoch
epoch = 50

# Since the file images are in a dirrectory we need to move them from the dirrectory into the model.  
# Keras as a function that makes this easy. Documentaion is here: https://keras.io/preprocessing/image/

train_generator = train_datagen.flow_from_directory(
    train_dir,  # The directory where the train data is located
    target_size=(150, 150),
    # Reshape the image to 150 by 150 pixels. This is important because it makes sure all images are the same size.
    batch_size=20,  # We will take images in batches of 20.
    class_mode='binary')  # The classification is binary.

validataion_generator = train_datagen.flow_from_directory(
    validation_dir,
    target_size=(150, 150),
    batch_size=20,
    class_mode='binary')

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(150, 150),
    batch_size=20,
    class_mode='binary')

# Now we build the model.

backend.clear_session()
model = models.Sequential()

model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))
model.add(layers.MaxPool2D((2, 2)))
model.add(BatchNormalization())

model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPool2D((2, 2)))
model.add(BatchNormalization())

model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPool2D((2, 2)))
model.add(BatchNormalization())

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dropout(0.5))

model.add(layers.Dense(1, activation='sigmoid'))

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit_generator(
    # The image data must come from the image generator that takes the images from the correct dirrectory. https://keras.io/models/sequential/
    train_generator,  # Images are taken from the train_generator
    steps_per_epoch=100,  # The number of steps from the train_generator before one epoch if finished.
    # 100 steps * 20 batch size in train generator = 2000 training images per epoch. This way each traning image will be sampled once per epoch.
    epochs=epoch,  # Train data for 50 epochs
    validation_data=validataion_generator,  # Take data from the validataion generator
    validation_steps=50,  # 50 steps * 20 batch size in validation generator = 1000 validation images per epoch
    verbose=2,
    callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)])

test_loss, test_acc = model.evaluate_generator(test_generator,
                                               steps=50)  # Test images are in a dirrectory so they must flow from dirrectory.
# 50 steps * 20 batch size in test generator = 1000 test images per epoch
print('base_model_test_acc:', test_acc)

print(
    'The above model came out with about 70% accuracy. Which is pretty good considering we only used 2000 training images!')

# Now lets improve using data augmentation.
# Data augmentation allows us to randomally transform images before sending them to the model for training.  
# The random transformation changes the images into 'new' images and allows for an increase in traning data without have additional images. 
# https://keras.io/preprocessing/image/ 

train_datagen2 = ImageDataGenerator(
    rescale=1. / 255,  # The image augmentaion function in Keras
    rotation_range=40,  # Rotate the images randomly by 40 degrees
    width_shift_range=0.2,  # Shift the image horizontally by 20%
    height_shift_range=0.2,  # Shift the image veritcally by 20%
    zoom_range=0.2,  # Zoom in on image by 20%
    horizontal_flip=True,  # Flip image horizontally
    fill_mode='nearest')  # How to fill missing pixels after a augmentaion opperation

test_datagen2 = ImageDataGenerator(
    rescale=1. / 255)  # Never apply data augmentation to test data. You only want to normalize and resize test data.

train_generator2 = train_datagen2.flow_from_directory(
    train_dir,
    target_size=(150, 150),
    batch_size=20,
    class_mode='binary')

validataion_generator2 = train_datagen2.flow_from_directory(
    validation_dir,
    target_size=(150, 150),
    batch_size=20,
    class_mode='binary')

test_generator2 = test_datagen2.flow_from_directory(  # Resize test data
    test_dir,
    target_size=(150, 150),
    batch_size=20,
    class_mode='binary')

backend.clear_session()
model_aug = models.Sequential()

model_aug.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))
model_aug.add(layers.MaxPool2D((2, 2)))
model_aug.add(BatchNormalization())
model_aug.add(layers.Conv2D(32, (3, 3), activation='relu'))
model_aug.add(layers.MaxPool2D((2, 2)))
model_aug.add(BatchNormalization())
model_aug.add(layers.Conv2D(32, (3, 3), activation='relu'))
model_aug.add(layers.MaxPool2D((2, 2)))
model_aug.add(BatchNormalization())
model_aug.add(layers.Flatten())
model_aug.add(layers.Dense(64, activation='relu'))
model_aug.add(layers.Dropout(0.5))

model_aug.add(layers.Dense(1, activation='sigmoid'))

model_aug.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

history = model_aug.fit_generator(
    train_generator2,
    steps_per_epoch=400,
    epochs=epoch,
    validation_data=validataion_generator2,
    validation_steps=50,
    verbose=2,
    callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)])

test_loss, test_acc = model_aug.evaluate_generator(test_generator2, steps=50)

print('Data_Augmentation_test_acc:', test_acc)

print('An inprovment, but not a suprise. Having more data helps our accuracy.')

# Your Turn
# Build and optimize another model. 
# Use weights from a different pretrained network (ie, ResNet, Inception, etc. not VGG. https://keras.io/applications/) from the Keras library. Optimize the model by adding additional layers, regularization, change activaction, adjust data augmentation etc.

from tensorflow.keras.applications import InceptionV3

backend.clear_session()
conv_incep = InceptionV3(weights='imagenet',
                         include_top=False,
                         input_shape=(150, 150, 3))

print('InceptionV3 base summary:', conv_incep.summary())

modelincep = models.Sequential()
modelincep.add(conv_incep)
modelincep.add(layers.Flatten())
modelincep.add(layers.Dense(512, activation='relu'))
modelincep.add(layers.Dense(1, activation='sigmoid'))

modelincep.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                   loss='binary_crossentropy',
                   metrics=['accuracy'])

history = modelincep.fit_generator(
    train_generator2,
    steps_per_epoch=200,
    epochs=epoch,
    validation_data=validataion_generator2,
    validation_steps=50,
    verbose=2,
    callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)])

test_loss, test_acc = modelincep.evaluate_generator(test_generator2, steps=50)

print('InceptionV3_frozen_test_acc:', test_acc)

# Freezing
backend.clear_session()

incep_2 = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

for layer in incep_2.layers[:-4]:
    layer.trainable = False
for layer in incep_2.layers:
    print(layer, layer.trainable)

print('InceptionV3 model 2 summary:', incep_2.summary())

modelincep_train = models.Sequential()
modelincep_train.add(incep_2)
modelincep_train.add(layers.Flatten())
modelincep_train.add(layers.Dense(512, activation='relu'))
modelincep_train.add(layers.Dense(1, activation='sigmoid'))

modelincep_train.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                         loss='binary_crossentropy',
                         metrics=['accuracy'])

history = modelincep_train.fit_generator(
    train_generator2,
    steps_per_epoch=200,
    epochs=epoch,
    validation_data=validataion_generator2,
    verbose=2,
    callbacks=[EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)])

test_loss, test_acc = modelincep_train.evaluate_generator(test_generator2, steps=50)

print('incep_train_test_acc:', test_acc)
print('The best model yet')
